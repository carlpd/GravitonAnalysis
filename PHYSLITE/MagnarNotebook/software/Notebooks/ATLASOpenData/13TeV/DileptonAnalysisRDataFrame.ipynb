{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When running this notebook via the Galaxy portal\n",
    "You can access your data via the dataset number. Using a Python kernel, you can access dataset number 42 with ``handle = open(get(42), 'r')``.\n",
    "To save data, write your data to a file, and then call ``put('filename.txt')``. The dataset will then be available in your galaxy history.\n",
    "<br><br>Note that if you are putting/getting to/from a different history than your default history, you must also provide the history-id.\n",
    "<br><br>More information including available galaxy-related environment variables can be found at https://github.com/bgruening/docker-jupyter-notebook. This notebook is running in a docker container based on the Docker Jupyter container described in that link.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATLAS OpenData with RDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses <a href=\"https://root.cern/doc/master/classROOT_1_1RDataFrame.html\" target=\"_blank\">RDataFrame</a> in ROOT to perform an analysis of the 13 TeV ATLAS OpenData. It needs ROOT version >= 6.24/02. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes and imports\n",
    "\n",
    "The follwing cells includes the needed libraries as well as a helper function with some useful function to retrieve all the available samples and the categorization of backgrounds. See the ouput for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "#ROOT.EnableImplicitMT()\n",
    "import os\n",
    "import import_ipynb\n",
    "import setPath\n",
    "from Input.OpenDataPandaFramework13TeV import *\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not really needed since lumi is set as a public variable in include above\n",
    "lumi = 10064.0\n",
    "print('Run on data corresponding to {:.2f} fb^-1'.format(lumi/ 1000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the samples and categories\n",
    "\n",
    "Set the path to the location of the openData ntuples and the <a href=\"http://opendata.atlas.cern/release/2020/documentation/datasets/files.html\" target=\"_blank\">dataset</a> you want to run over. The *initialize()* checks for all available samples in the directory and categorize them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/storage/shared/data/fys5555/ATLAS_opendata/\"\n",
    "#dir = \"/storage/shared/data/fys5555/ATLAS_opendata/RNTuples/\" #use RNtuple\n",
    "ana = \"2lep\"\n",
    "mcfiles = initialize(dir+\"/\"+ana+\"/MC\")\n",
    "datafiles = initialize(dir+\"/\"+ana+\"/Data\")\n",
    "allfiles = z = {**mcfiles, **datafiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = allfiles.keys()\n",
    "df = {}\n",
    "for p in processes:\n",
    "    samples = []\n",
    "    datafrs = []\n",
    "    ns = 0\n",
    "    for d in allfiles[p][\"files\"]:\n",
    "        if ns == 0:\n",
    "            fold = \"/\".join(d.split(\"/\")[:-1])\n",
    "            haddfile = \"%s/%s.root\"%(fold,p)\n",
    "            if os.path.isfile(haddfile): \n",
    "                break\n",
    "        samples.append(d)\n",
    "        ns += 1\n",
    "    if len(samples):\n",
    "        print(\"Using %i unhadded files for %s\"%(len(samples),p))\n",
    "        df[p] = ROOT.RDataFrame(\"mini\", samples)\n",
    "    else:\n",
    "        print(\"Using hadded file %s for %s\"%(haddfile,p))\n",
    "        df[p] = ROOT.RDataFrame(\"mini\", haddfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! g++ -shared -fPIC -o Cfunctions.so /storage/shared/software/Input/Cfunctions.cxx `root-config --cflags --glibs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include a pre-compiled c++ library of useful functions. Do ROOT.help() to see content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.gSystem.AddDynamicPath(\"/storage/shared/software/Input/\")\n",
    "ROOT.gROOT.ProcessLine(\".include /storage/shared/software/Input/\");\n",
    "ROOT.gInterpreter.AddIncludePath(\"/storage/shared/software/Input/\");\n",
    "ROOT.gInterpreter.Declare('#include \"/storage/shared/software/Input/Cfunctions.h\"') # Header with the definition of the myFilter function\n",
    "ROOT.gSystem.Load(\"Cfunctions.so\") # Library with the myFilter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "for p in processes:\n",
    "    \n",
    "    print(\"Looking at %s\"%p)\n",
    "    \n",
    "    # Define good leptons using pT > 25 GeV and isolation\n",
    "    df[p] = df[p].Define(\"goodLEP\",\"lep_pt > 25000 && lep_etcone20/lep_pt < 0.15 && lep_ptcone30/lep_pt < 0.15\")\n",
    "    #df[p] = df[p].Define(\"goodLEP\",\"1\")\n",
    "    df[p] = df[p].Define(\"n_goodLEP\",\"Sum(goodLEP)\")\n",
    "    # Find number of good leptons\n",
    "    df[p] = df[p].Filter(\"n_goodLEP == 2\",\"2 good leptons\")\n",
    "    # Calculate flavour and charge of the two leptons\n",
    "    df[p] = df[p].Define(\"isOS\",\"isOS(lep_charge[goodLEP])\")\n",
    "    df[p] = df[p].Define(\"isSF\",\"isSF(lep_type[goodLEP])\")\n",
    "    # Cut on SF + OS\n",
    "    df[p] = df[p].Filter(\"isSF\",\"Same flavour\")\n",
    "    df[p] = df[p].Filter(\"isOS\",\"Opposite sign\")\n",
    "    # Compute mll\n",
    "    df[p] = df[p].Define(\"mll\",\"ComputeInvariantMass(lep_pt[goodLEP],lep_eta[goodLEP],lep_phi[goodLEP],lep_E[goodLEP])\")\n",
    "    \n",
    "    # Compute costheta*\n",
    "    df[p] = df[p].Define(\"costhstar\",\"costhetastar(lep_pt[goodLEP],lep_eta[goodLEP],lep_phi[goodLEP],lep_E[goodLEP])\")\n",
    "    \n",
    "    \n",
    "    # Calculate weight for scaling (inlcudes scaling to luminosisty)\n",
    "    if allfiles[p][\"type\"] == \"data\":\n",
    "        df[p] = df[p].Define(\"weight\", \"1.0\")\n",
    "    else:\n",
    "        df[p] = df[p].Define(\"weight\", \"scaleFactor_ELE * scaleFactor_MUON * scaleFactor_LepTRIGGER * scaleFactor_PILEUP * mcWeight * (XSection * {} / SumWeights)\".format(lumi))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = df[\"Gmumu\"].Histo1D(ROOT.RDF.TH1DModel(p, \"XSection\",200, 0, 2), \"XSection\")\n",
    "cols = ROOT.vector('string')()\n",
    "cols.push_back(\"XSection\")\n",
    "cols.push_back(\"channelNumber\")\n",
    "cols.push_back(\"scaleFactor_ELE\")\n",
    "cols.push_back(\"scaleFactor_MUON\")\n",
    "cols.push_back(\"scaleFactor_LepTRIGGER\")\n",
    "cols.push_back(\"scaleFactor_PILEUP\")\n",
    "cols.push_back(\"mcWeight\")\n",
    "cols.push_back(\"XSection\")\n",
    "cols.push_back(\"SumWeights\")\n",
    "d = df[\"Gee\"].Display(cols)\n",
    "print(d.AsString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d2 = df[\"topX\"].Display(cols)\n",
    "#d2.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create canvas with pad\n",
    "##c = ROOT.TCanvas(\"c\", \"\", 900, 700)\n",
    "#c.Draw()\n",
    "#pad = ROOT.TPad(\"upper_pad\", \"\", 0, 0, 1, 1)\n",
    "#pad.SetTickx(False)\n",
    "#pad.SetTicky(False)\n",
    "#pad.SetLogy()\n",
    "#pad.Draw()\n",
    "#pad.cd()\n",
    "#hist.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df[\"Zjets\"].GetColumnNames():\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining the histograms axis ranges and number of bins must be set. There are some pre-defined values for some of the available variables alread stored in _plotdic_. You can easilly add new variables or change the current ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available variables : %s\"%\", \".join(plotdic.keys()))\n",
    "print(\"Structure of dictionary is as follows : \\n\",plotdic[\"lep_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "histos = {}\n",
    "variables = [\"costhstar\",\"met_et\",\"mll\",\"lep_pt\",\"lep_E\",\"jet_pt\"]\n",
    "allhistos = []\n",
    "for v in variables:\n",
    "    if not v in plotdic.keys():\n",
    "        print(\"ERROR \\t Could not find plot information for %s\"%v)\n",
    "    histos[v] = {}\n",
    "    for p in processes:\n",
    "        histos[v][p] = df[p].Histo1D(ROOT.RDF.TH1DModel(p+\"_\"+v, v, plotdic[v]['nbin'], plotdic[v]['nmin'], plotdic[v]['nmax']), v, \"weight\")\n",
    "        allhistos.append(histos[v][p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Number of histograms = %i\"%len(allhistos))\n",
    "ROOT.RDF.RunGraphs(allhistos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the background wrt to size (for plotting)\n",
    "\n",
    "# First; get the sum of weights for each histogram\n",
    "dir_sumw = {}\n",
    "for v in variables:\n",
    "    if not v in dir_sumw.keys():\n",
    "        dir_sumw[v] = {}\n",
    "    for p in processes:\n",
    "        dir_sumw[v][p] = histos[v][p].GetSumOfWeights()\n",
    "        \n",
    "# Second; sort them accordingly\n",
    "sorted_sumw = {}\n",
    "for v in dir_sumw.keys():\n",
    "    sorted_sumw[v] = []\n",
    "    while True:\n",
    "        maxi = -999\n",
    "        for p in dir_sumw[v].keys():\n",
    "            if (dir_sumw[v][p] > maxi) and (not p in sorted_sumw[v]):\n",
    "                maxi = dir_sumw[v][p]\n",
    "                maxip = p\n",
    "        sorted_sumw[v].append(maxip)\n",
    "        if len(sorted_sumw[v]) == len(dir_sumw[v].keys()): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#import time\n",
    "mcbkg = {}\n",
    "data = {}\n",
    "nv = 1\n",
    "for v in variables:\n",
    "    print(\"Doing variable %s (%i/%i)\"%(v,nv,len(variables)+1))\n",
    "    mcbkg[v] = []\n",
    "    for p in reversed(sorted_sumw[v]):\n",
    "        if allfiles[p][\"type\"] == \"bkg\":\n",
    "            mcbkg[v].append(histos[v][p].GetValue())\n",
    "        elif allfiles[p][\"type\"] == \"data\":\n",
    "            data[v] = histos[v][p].GetValue()\n",
    "    nv += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sumw[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add legend\n",
    "legend = ROOT.TLegend(0.60, 0.60, 0.8, 0.85)\n",
    "legend.SetTextFont(42)\n",
    "legend.SetFillStyle(0)\n",
    "legend.SetBorderSize(0)\n",
    "legend.SetTextSize(0.04)\n",
    "#legend.SetTextAlign(32)\n",
    "\n",
    "donotplot = [\"Zjetsincl\",\"Wjetsincl\"]\n",
    "\n",
    "# Draw stack with MC contributions\n",
    "stack = ROOT.THStack()\n",
    "\n",
    "# Set the variable to plot\n",
    "v = \"costhstar\"\n",
    "for h in mcbkg[v]:\n",
    "    p = h.GetName().split(\"_\")[0]\n",
    "    if p in bkg_plot_dic.keys():\n",
    "        print(p)\n",
    "        color = bkg_plot_dic[p][\"color\"]\n",
    "    else:\n",
    "        print(\"Could not find color for %s\"%p)\n",
    "        color = ROOT.kWhite\n",
    "    print(color)\n",
    "    #print(h.GetName()) \n",
    "    if h.GetName().split(\"_\")[0] in donotplot: continue\n",
    "    h.SetLineWidth(1)\n",
    "    h.SetLineColor(1)\n",
    "    h.SetFillColor(ROOT.TColor.GetColor(*color))\n",
    "    h.SetDirectory(0)\n",
    "    legend.AddEntry(h,\"%-s\"%h.GetName().split(\"_\")[0].strip(),\"f\")\n",
    "    stack.Add(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create canvas with pad\n",
    "c = ROOT.TCanvas(\"c\", \"\", 900, 700)\n",
    "c.Draw()\n",
    "ROOT.gStyle.SetOptStat(0)\n",
    "pad = ROOT.TPad(\"upper_pad\", \"\", 0, 0.2, 1, 1.0)\n",
    "pad2 = ROOT.TPad(\"lower_pad\", \"\", 0, 0, 1, 0.2)\n",
    "pad.SetTickx(False)\n",
    "pad.SetTicky(False)\n",
    "pad.SetBottomMargin(0.005)\n",
    "pad.SetLogy()\n",
    "pad.Draw()\n",
    "pad2.Draw()\n",
    "pad.cd()\n",
    "stack.Draw(\"HIST\")\n",
    "\n",
    "sumMC = stack.GetStack().Last()\n",
    "sumMC.SetDirectory(0)\n",
    "sumMC.Divide(data[v])\n",
    "\n",
    "# Draw stack with MC contributions\n",
    "stack.GetXaxis().SetLabelSize(0.04)\n",
    "stack.GetXaxis().SetTitleSize(0.045)\n",
    "stack.GetXaxis().SetTitleOffset(1.3)\n",
    "stack.GetXaxis().SetTitle(\"m_{T}^{W#rightarrow l#nu} [GeV]\")\n",
    "stack.GetYaxis().SetTitle(\"Events\")\n",
    "stack.GetYaxis().SetLabelSize(0.04)\n",
    "stack.GetYaxis().SetTitleSize(0.045)\n",
    "stack.SetMaximum(1e7 * lumi*1e3)\n",
    "stack.SetMinimum(10)\n",
    "\n",
    "# Draw data\n",
    "data[v].SetMarkerStyle(20)\n",
    "data[v].SetMarkerSize(1.2)\n",
    "data[v].SetLineWidth(2)\n",
    "data[v].SetLineColor(ROOT.kBlack)\n",
    "data[v].Draw(\"E SAME\")\n",
    "\n",
    "# Draw legend\n",
    "legend.Draw(\"SAME\")\n",
    "\n",
    "# Add ATLAS label\n",
    "text = ROOT.TLatex()\n",
    "text.SetNDC()\n",
    "text.SetTextFont(72)\n",
    "text.SetTextSize(0.045)\n",
    "text.DrawLatex(0.21, 0.86, \"ATLAS\")\n",
    "text.SetTextFont(42)\n",
    "text.DrawLatex(0.21 + 0.09, 0.86, \"Open Data\")\n",
    "text.SetTextSize(0.04)\n",
    "text.DrawLatex(0.21, 0.80, \"#sqrt{{s}} = 13 TeV, {:.1f} fb^{{-1}}\".format(lumi / 1000.0))\n",
    "\n",
    "pad2.cd()\n",
    "pad2.SetGridy()\n",
    "pad2.SetTopMargin(0.01)\n",
    "pad2.SetTickx(False)\n",
    "pad2.SetTicky(False)\n",
    "sumMC.SetTitle(\"\")\n",
    "sumMC.GetXaxis().SetLabelSize(0.15)\n",
    "sumMC.GetYaxis().SetLabelSize(0.15)\n",
    "sumMC.SetMaximum(2)\n",
    "sumMC.SetMinimum(2)\n",
    "sumMC.Draw(\"ep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcuts = {}\n",
    "for p in processes:\n",
    "    allcuts[p] = df[p].Report()\n",
    "    print(p)\n",
    "    #allcuts.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertRDFCutflowToTex(cutflow, tex = False):\n",
    "    i = 0\n",
    "    tabstr = \"\"\n",
    "    stdstr = \"\"\n",
    "    for p in cutflow.keys():\n",
    "        tabstr += \"%s &\" %p\n",
    "        stdstr += \"%-10s \" %p\n",
    "        if i == 0:\n",
    "            headerstr = \"Background & \"\n",
    "            stdheadstr = \"%10s \"%\"Background\"\n",
    "            for c in cutflow[p]:\n",
    "                headerstr += \"%s & \" %c.GetName()\n",
    "                stdheadstr += \"| {:32s}\".format(c.GetName().strip())\n",
    "            headerstr = headerstr[:-2]+\"\\\\\\ \\n\"\n",
    "            stdheadstr += \"\\n\"\n",
    "        for c in cutflow[p]:\n",
    "            cname = c.GetName()\n",
    "            nevc1 = c.GetAll()\n",
    "            stdstr += \"| %9.0f %9.0f %5.1f %5.1f \"%(c.GetPass(),c.GetAll(),c.GetEff(),(c.GetPass()/nevc1)*100.)\n",
    "            cname = cname.replace(\">\",\"$>$\")\n",
    "            cname = cname.replace(\"<\",\"$<$\")\n",
    "            tabstr += \"$%.0f$ & $%.0f$ & $%.2f$ & $%.2f$ \"%(c.GetPass(),c.GetAll(),c.GetEff(),(c.GetPass()/nevc1)*100.)\n",
    "            i += 1\n",
    "        tabstr += \"\\\\\\ \\n\"\n",
    "        stdstr += \"\\n\"\n",
    "    if tex:\n",
    "        print(headerstr)\n",
    "        print(tabstr)\n",
    "    else:\n",
    "        print(stdheadstr)\n",
    "        print(stdstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertRDFCutflowToTex(allcuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "prefix_path = subprocess.run([\"root-config\", \"--prefix\"], capture_output=True).stdout.decode().strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
