{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When running this notebook via the Galaxy portal\n",
    "You can access your data via the dataset number. Using a Python kernel, you can access dataset number 42 with ``handle = open(get(42), 'r')``.\n",
    "To save data, write your data to a file, and then call ``put('filename.txt')``. The dataset will then be available in your galaxy history.\n",
    "<br><br>Note that if you are putting/getting to/from a different history than your default history, you must also provide the history-id.\n",
    "<br><br>More information including available galaxy-related environment variables can be found at https://github.com/bgruening/docker-jupyter-notebook. This notebook is running in a docker container based on the Docker Jupyter container described in that link.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilepton analysis  (Python) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a simple dilepton analysis, quite similar to the notebook called \"Dilepton_analysis_noData.ipynb\", but with some differences. The most obvious difference is that we here also include real data. This example also has a slightly more advanced event selection.  \n",
    "\n",
    "**Notice:** This is *only an example* on how to do this. Feel free to be creative, and to find better and/or more elegant ways of doing the various steps! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as R\n",
    "import import_ipynb\n",
    "import setPath\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from Input.OpenDataPandaFramework13TeV import *\n",
    "%jsroot on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to calculate MT2 (commonly used in SUSY analyses) you can add a pre-compiled library. It will be used in the event loop to calculate the MT2 of an event. Please look at https://www.hep.phy.cam.ac.uk/~lester/mt2/#Introduction_and_References for more information about the MT2 variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.gSystem.Load(\"/storage/shared/software/Input/CalcGenericMT2/src/libBinnedLik.so\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the analaysis to run (*1largeRjet1lep*, *1lep1tau*, *3lep*, *exactly2lep*, *GamGam*, *2lep*, *4lep*)\n",
    "\n",
    "Set the directory where you have downloaded the ATLAS OpenData samples you want to run over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendatadir = \"/storage/shared/data/fys5555/ATLAS_opendata/\"\n",
    "analysis = \"2lep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = R.TChain(\"mini\")\n",
    "data = R.TChain(\"mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all the background samples, category and their IDs can be found in **Infofile.txt**. The cross-section, efficiencies etc. needed for scaling are stored in the **Files_<---->**. We read these files and add all the samples to the TChain. We also (for later convenience) make a vector containing the dataset IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcfiles = initialize(opendatadir+\"/\"+analysis+\"/MC\")\n",
    "datafiles = initialize(opendatadir+\"/\"+analysis+\"/Data\")\n",
    "allfiles = z = {**mcfiles, **datafiles}\n",
    "Backgrounds = getBkgCategories() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCcat = {}\n",
    "for cat in allfiles:\n",
    "    for dsid in allfiles[cat][\"dsid\"]:\n",
    "        try:\n",
    "            MCcat[int(dsid)] = cat\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_IDs = []\n",
    "background.Reset()\n",
    "for b in Backgrounds:\n",
    "    i = 0\n",
    "    if not b in mcfiles.keys(): continue\n",
    "    for mc in mcfiles[b][\"files\"]:\n",
    "        if not os.path.isfile(mc): continue\n",
    "        try:\n",
    "            dataset_IDs.append(int(mcfiles[b][\"dsid\"][i]))\n",
    "            background.Add(mc)\n",
    "        except:\n",
    "            print(\"Could not get DSID for %s. Skipping\"%mc)\n",
    "        i += 1\n",
    "nen = background.GetEntries()\n",
    "print(\"Added %i entries for backgrounds\"%(nen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Reset(); \n",
    "for d in datafiles[\"data\"][\"files\"]:  \n",
    "    if not os.path.isfile(d): continue\n",
    "    data.Add(d)\n",
    "nen = data.GetEntries()\n",
    "print(\"Added %i entries for backgrounds\"%(nen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making (a lot of) histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read our dataset we want to start analyzing the data. To do so we need to put the data into histograms. For reasons that will become clear later in the analysis we must (for each variable) make one histogram per dataset ID. (We have 31 background samples, so if we want to study 10 variables we have to make 310 histograms!) For best dealing with all these histograms we can use dictionaries (Python) or maps (C++). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll = {}; hist_lep_pt = {}; hist_met = {}; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset_IDs: \n",
    "    hist_mll[i] = R.TH1F() \n",
    "    hist_lep_pt[i] = R.TH1F()\n",
    "    hist_met[i] = R.TH1F()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset_IDs: \n",
    "    hist_mll[i].SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "    hist_lep_pt[i].SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "    hist_met[i].SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "    hist_mll[i].SetBins(20,0,500); \n",
    "    hist_lep_pt[i].SetBins(20,0,1000);\n",
    "    hist_met[i].SetBins(20,0,500); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data it is only necessary with one histogram for each variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d = R.TH1F(); \n",
    "hist_lep_pt_d = R.TH1F(); \n",
    "hist_met_d = R.TH1F(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d.SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "hist_lep_pt_d.SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "hist_met_d.SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "hist_mll_d.SetBins(20,0,500); \n",
    "hist_lep_pt_d.SetBins(20,0,1000);\n",
    "hist_met_d.SetBins(20,0,500); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve lumi from library\n",
    "%store -r lumi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fill the histograms \n",
    "We can now loop over all events in our dataset, implement desired cuts, and fill the histograms we created above. In this example we choose only events containing exactly to same flavour leptons with opposite charge (i.e. $e^+e^-$ or $\\mu^+\\mu^-$). \n",
    "Before starting the loop we extract the total number of entries (events) in the TChain. We also make [TLorentzVector](https://root.cern.ch/doc/master/classTLorentzVector.html)s, which are very practical for handling the kinematics of the leptons, e.g. calculating the invariant mass of the two leptons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset_IDs: \n",
    "    hist_mll[i].Reset(); \n",
    "    hist_lep_pt[i].Reset(); \n",
    "    hist_met[i].Reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d.Reset(); \n",
    "hist_lep_pt_d.Reset(); \n",
    "hist_met_d.Reset(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = R.TLorentzVector() \n",
    "l2 = R.TLorentzVector() \n",
    "dileptons = R.TLorentzVector() \n",
    "met = R.TLorentzVector() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the cell where the analysis is performed. Note that the cell needs to be run twice:\n",
    "\n",
    "1. with data = 0 to run over MC\n",
    "2. with data = 1 to run over data\n",
    "\n",
    "Note that the MC running takes ~5 minutes for 3lep analysis. Much(!!!) more time for e.g. 2lep analysis! Data running is relatively fast for 3lep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "isData = 1; \n",
    "\n",
    "if isData == 1: ds = data \n",
    "else: ds = background     \n",
    "\n",
    "i = 0   \n",
    "for event in ds: \n",
    "    \n",
    "    if i%100000 == 0 and i>0: \n",
    "        print(\"Total events %i/%i\"%(i,ds.GetEntries()))\n",
    "    i += 1 \n",
    "    ## Data quality cuts: \n",
    "    \n",
    "    #if i > 10000: break\n",
    "    \n",
    "    #if ds.passGRL == 0: continue\n",
    "    #if ds.hasGoodVertex == 0: continue\n",
    "    #if(trigM == 0 && trigE == 0){ continue; } \n",
    "\n",
    "    ## Event selection:\n",
    "    \n",
    "    ## Cut #1: Require (exactly) 2 leptons\n",
    "    if not ds.lep_n == 3: continue\n",
    "    ## Cut #2: Require opposite charge\n",
    "    if ds.lep_charge[0] == ds.lep_charge[1]: continue\n",
    "    ## Cut #3: Require same flavour (2 electrons or 2 muons)\n",
    "    if not ds.lep_type[0] == ds.lep_type[1]: continue\n",
    "\n",
    "    \n",
    "    ## Require \"good leptons\": \n",
    "    \n",
    "    if ds.lep_pt[0]/1000.0 < 25: continue\n",
    "    if ds.lep_etcone20[0]/ds.lep_pt[0] > 0.15: continue\n",
    "    if ds.lep_ptcone30[0]/ds.lep_pt[0] > 0.15: continue\n",
    "    #if not (ds.lep_flag[0] & 512): continue\n",
    "        \n",
    "    if ds.lep_pt[1]/1000.0 < 25: continue\n",
    "    if ds.lep_etcone20[1]/ds.lep_pt[1] > 0.15: continue\n",
    "    if ds.lep_ptcone30[1]/ds.lep_pt[1] > 0.15: continue\n",
    "    #if not (ds.lep_flag[1] & 512): continue\n",
    "\n",
    "    \n",
    "    ## Set Lorentz vectors: \n",
    "    l1.SetPtEtaPhiE(ds.lep_pt[0]/1000., ds.lep_eta[0], ds.lep_phi[0], ds.lep_E[0]/1000.);\n",
    "    l2.SetPtEtaPhiE(ds.lep_pt[1]/1000., ds.lep_eta[1], ds.lep_phi[1], ds.lep_E[1]/1000.);\n",
    "    ## Variables are stored in the TTree with unit MeV, so we need to divide by 1000 \n",
    "    ## to get GeV, which is a more practical and commonly used unit. \n",
    "\n",
    "    dileptons = l1 + l2;   \n",
    "\n",
    "    met.SetPtEtaPhiE(ds.met_et/1000., 0.0, ds.met_phi ,0.0)\n",
    "\n",
    "    # calculate the mt2 - comment out if you're not interested\n",
    "    mycalc = R.ComputeMT2(l1,l2,met,0.,0.)\n",
    "    mt2 = mycalc.Compute()\n",
    "\n",
    "    if isData == 1:\n",
    "        hist_mll_d.Fill(dileptons.M());\n",
    "        hist_lep_pt_d.Fill(l1.Pt());\n",
    "        hist_lep_pt_d.Fill(l2.Pt()); \n",
    "        hist_met_d.Fill(ds.met_et/1000);                       \n",
    "    else: \n",
    "        W = ((ds.mcWeight)*(ds.scaleFactor_PILEUP)*\n",
    "             (ds.scaleFactor_ELE)*(ds.scaleFactor_MUON)*\n",
    "             (ds.scaleFactor_BTAG)*(ds.scaleFactor_LepTRIGGER))*((ds.XSection*lumi)/ds.SumWeights)\n",
    "        hist_mll[ds.channelNumber].Fill(dileptons.M(), W);\n",
    "        hist_lep_pt[ds.channelNumber].Fill(l1.Pt(), W);\n",
    "        hist_lep_pt[ds.channelNumber].Fill(l2.Pt(), W); \n",
    "        hist_met[ds.channelNumber].Fill(ds.met_et/1000, W);   \n",
    "        \n",
    "print(\"Done!\")\n",
    "if isData == 0:\n",
    "    print(\"Remebered to run over data? No? Set data = 1 at the top and run again\")\n",
    "else:\n",
    "    print(\"Remebered to run over MC? No? Set data = 0 at the top and run again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale and classify the histograms (MC only) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are ready to make plots we need to do some further processing of the histograms we made above. The information necessary for doing the two steps below is found in the file **Infofile.txt**.   \n",
    "1. We need to **scale** the histograms to the right cross section and luminosity. Why? When making the MC samples a certain number of events is simulated, which will usually not correspond to the number of events in our data. The expected number of events from a certain kind of process is given by $N=\\sigma L$, where $\\sigma$ is the cross section and $L$ is the integrated luminosity. Therefore we need to scale each histogram by a scale factor <br> <br>\n",
    "$$sf = \\frac{N}{N_{MC}} = \\frac{ \\sigma L }{N_{MC}},$$ <br>  where $N_{MC}$ is the number of generated MC events.  <br> <br>\n",
    "2. We also need to **classify** the background processes into different categories. This is necessary when we eventually want to make the characteristic colorful background plots you might have seen before.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Make new histograms \n",
    "Maybe a bit depressingly we have to make a set of new histograms, this time corresponding to the different background categories, instead of the dataset IDs. Notice that these new histograms are made in a very similar way as above, i.e. with the same range and binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_mll = {}; H_lep_pt = {}; H_met = {}; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Backgrounds: \n",
    "    H_mll[i] = R.TH1F() \n",
    "    H_lep_pt[i] = R.TH1F() \n",
    "    H_met[i] = R.TH1F() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Backgrounds: \n",
    "    H_mll[i].SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "    H_lep_pt[i].SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "    H_met[i].SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "    H_mll[i].SetBins(20,0,500); \n",
    "    H_lep_pt[i].SetBins(20,0,1000);\n",
    "    H_met[i].SetBins(20,0,500); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scale and add histograms \n",
    "Now we read our info file, scale all (old) histograms, and then add them to the new histograms we just defined.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Backgrounds: \n",
    "    H_mll[i].Reset(); \n",
    "    H_lep_pt[i].Reset(); \n",
    "    H_met[i].Reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dsid in hist_mll.keys(): \n",
    "    \n",
    "    Type = MCcat[dsid]\n",
    "    \n",
    "    H_mll[Type].Add(hist_mll[dsid]); \n",
    "    H_lep_pt[Type].Add(hist_lep_pt[dsid]); \n",
    "    H_met[Type].Add(hist_met[dsid]); \n",
    "    \n",
    "infofile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Color the histograms \n",
    "Make yet another map, this time containing the colors you want the backgrounds to have, and then set the colors of your histograms. Note that colors are defined by integers in ROOT. If you are not happy with the colors chosen below you can have look at the [TColor](https://root.cern.ch/doc/master/classTColor.html) class reference for more options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[\"Diboson\"] = R.kGreen; \n",
    "colors[\"Zjets\"] = R.kYellow; \n",
    "colors[\"ttbar\"] = R.kRed;\n",
    "colors[\"singleTop\"] = R.kBlue-7; \n",
    "colors[\"Wjets\"] = R.kBlue+3; \n",
    "colors[\"topX\"] = R.kOrange+1; \n",
    "colors[\"Higgs\"] = R.kMagenta; \n",
    "colors[\"Wjetsincl\"] = R.kBlue-10;\n",
    "colors[\"Zjetsincl\"] = R.kYellow-9;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in Backgrounds: \n",
    "    H_mll[h].SetFillColor(colors[h]); \n",
    "    H_met[h].SetFillColor(colors[h]);\n",
    "    H_lep_pt[h].SetFillColor(colors[h]);\n",
    "    \n",
    "    H_mll[h].SetLineColor(colors[h]); \n",
    "    H_met[h].SetLineColor(colors[h]);\n",
    "    H_lep_pt[h].SetLineColor(colors[h]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stack and plot the histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have arrived to the part where we can plot the results of all the work done above. For each variable we need to stack the backgrounds on top of each other, which is done by using the [THStack](https://root.cern.ch/doc/master/classTHStack.html) class. In the example below we do this for two variables; invariant mass and missing $E_T$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_mll = R.THStack(\"Invariant mass\", \"\");\n",
    "stack_met = R.THStack(\"Missing ET\", \"\"); \n",
    "stack_lep_pt = R.THStack(\"Lepton pT\", \"\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in Backgrounds: \n",
    "    stack_mll.RecursiveRemove(H_mll[h]); ## Remove previously stacked histograms  \n",
    "    stack_met.RecursiveRemove(H_met[h]);\n",
    "    stack_lep_pt.RecursiveRemove(H_lep_pt[h]);\n",
    "    stack_mll.Add(H_mll[h]); \n",
    "    stack_met.Add(H_met[h]);\n",
    "    stack_lep_pt.Add(H_lep_pt[h]); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a legend (see [TLegend](https://root.cern.ch/doc/master/classTLegend.html)), and add  the different backgrounds. Next we make a canvas (see [TCanvas](https://root.cern.ch/doc/master/classTCanvas.html)), which is allways necessary when we want to make a plot. Then you draw the stack and the legend, and display them by drawing the canvas. We can also specify axis labels and a bunch of other stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.gStyle.SetLegendBorderSize(0); ## Remove (default) border around legend \n",
    "leg = R.TLegend(0.65, 0.60, 0.9, 0.85); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg.Clear();\n",
    "for i in Backgrounds: \n",
    "    leg.AddEntry(H_mll[i], i, \"f\")  ## Add your histograms to the legend\n",
    "leg.AddEntry(hist_mll_d, \"Data\", \"lep\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = R.TCanvas(\"c\", \"c\", 600, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.gPad.SetLogy() ## Set logarithmic y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d.SetLineColor(R.kBlack); \n",
    "hist_mll_d.SetMarkerStyle(R.kFullCircle); \n",
    "hist_mll_d.SetMarkerColor(R.kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_mll.Draw(\"hist\"); \n",
    "stack_mll.SetMaximum(1E6); \n",
    "stack_mll.SetMinimum(1); \n",
    "stack_mll.GetYaxis().SetTitle(\"# events\");\n",
    "stack_mll.GetYaxis().SetTitleOffset(1.3); \n",
    "stack_mll.GetXaxis().SetTitle(\"m_{ll} (GeV)\");\n",
    "stack_mll.GetXaxis().SetTitleOffset(1.3);\n",
    "hist_mll_d.Draw(\"same E\"); \n",
    "leg.Draw();\n",
    "C.Draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_met_d.SetLineColor(R.kBlack); \n",
    "hist_met_d.SetMarkerStyle(R.kFullCircle); \n",
    "hist_met_d.SetMarkerColor(R.kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_met.Draw(\"hist\"); \n",
    "stack_met.SetMaximum(1E6); \n",
    "stack_met.GetYaxis().SetTitle(\"# events\");\n",
    "stack_met.GetYaxis().SetTitleOffset(1.3); \n",
    "stack_met.GetXaxis().SetTitle(\"E_{T}^{miss} (GeV)\");\n",
    "stack_met.GetXaxis().SetTitleOffset(1.3);\n",
    "hist_met_d.Draw(\"same e\"); \n",
    "leg.Draw();\n",
    "C.Draw(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lep_pt_d.SetLineColor(R.kBlack); \n",
    "hist_lep_pt_d.SetMarkerStyle(R.kFullCircle); \n",
    "hist_lep_pt_d.SetMarkerColor(R.kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_lep_pt.Draw(\"hist\"); \n",
    "stack_lep_pt.SetMaximum(1E6); \n",
    "stack_lep_pt.GetYaxis().SetTitle(\"# events\");\n",
    "stack_lep_pt.GetYaxis().SetTitleOffset(1.3); \n",
    "stack_lep_pt.GetXaxis().SetTitle(\"p_{T} (GeV)\");\n",
    "stack_lep_pt.GetXaxis().SetTitleOffset(1.3);\n",
    "hist_lep_pt_d.Draw(\"same e\"); \n",
    "leg.Draw();\n",
    "C.Draw(); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
